{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d2b113",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ef2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main of the project\n",
    "\n",
    "# libraries\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import os\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import mglearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "import statistics as st\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score \n",
    "from sklearn.cluster import KMeans \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import *\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# custom libraries\n",
    "from Geographycal_functions import drop_non_geolocalised\n",
    "from Geographycal_functions import localize_tweets\n",
    "from Geographycal_functions import localize_USA\n",
    "from Preprocessing_functions import parallelize_dataframe\n",
    "from Preprocessing_functions import preprocessing\n",
    "from Preprocessing_functions import safe_drop_attr\n",
    "\n",
    "# visualize progresses\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3593a",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d9366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\".\\Processed_data\\States_mined.csv\"):                       # we can choose one of the two\n",
    "    state_df = pd.read_csv(\".\\Processed_data\\States_mined.csv\")\n",
    "    undone_flag = False\n",
    "else:\n",
    "    # import the raw data\n",
    "    data_donald = pd.read_csv(\"hashtag_donaldtrump.csv\", lineterminator='\\n')\n",
    "    data_joe = pd.read_csv(\"hashtag_joebiden.csv\", lineterminator='\\n')\n",
    "    \n",
    "    # joining the two datasets dropping duplicates!!\n",
    "    data_all = pd.concat([data_joe,data_donald]).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # flag to be used in the next steps of the project\n",
    "    undone_flag = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6cc2b",
   "metadata": {},
   "source": [
    "# Geolocalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a085e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    print(\"Geolocalization\")\n",
    "    data_all = drop_non_geolocalised(data_all, \"lat\", \"long\")\n",
    "    geo_df = localize_tweets(data_all, \"World Tweet data distribution\")\n",
    "    df = localize_USA(geo_df, \"USA Tweets data distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389ec99",
   "metadata": {},
   "source": [
    "# Preprocessing and text mining\n",
    "We considered only the data localized in the USA.\n",
    "\n",
    "This diminished the number of instances by a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea130fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    # data to drop\n",
    "    to_be_deleted = [\"tweet_id\", \"source\", \"user_id\", \"user_join_date\", \"user_location\", \"continent\", \"collected_at\"]\n",
    "    # drop\n",
    "    df = safe_drop_attr(df, to_be_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce09ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    # Text mining\n",
    "    df = parallelize_dataframe(df, preprocessing, n_cores=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4fcda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    # save the data into a folder\n",
    "    data_donald.to_csv(\".\\Processed_data\\Df_mined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6595b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    print(\"The df's type is: {}. Therefore I save a copy and covert it into a pandas dataframe object\".format(type(df)))\n",
    "    geo_df = df.copy()\n",
    "    df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2732c",
   "metadata": {},
   "source": [
    "# Create the ML dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6bbfd6",
   "metadata": {},
   "source": [
    "Since we are squeezing all our data into 51 elements, we want to add to each state as much information about the statistical population they represents, we are therefore adding some statistics to the dataframe.\n",
    "Each statistic is related to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a78e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    df.drop(columns=[\"DRAWSEQ\", \"index_right\", ],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e929479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    # initialize an empty list where to append the statistics\n",
    "    state_list = []\n",
    "    # group the data by state\n",
    "    df_groupby = df.groupby(\"STATE_NAME\")\n",
    "    # averages\n",
    "    state_list.append(df_groupby.mean(numeric_only=True).add_suffix(\"_Mean\"))\n",
    "    # skewness\n",
    "    state_list.append(df_groupby.skew(numeric_only=True).add_suffix(\"_Skewness\"))  \n",
    "    # median\n",
    "    state_list.append(df_groupby.median(numeric_only=True).add_suffix(\"_Median\"))  \n",
    "    # count the tweets\n",
    "    state_list.append(df_groupby.count().add_suffix(\"_Counts\"))  \n",
    "    # variance\n",
    "    state_list.append(df_groupby.var().add_suffix(\"_Variance\"))\n",
    "    # standard deviation\n",
    "    state_list.append(df_groupby.std().add_suffix(\"_Std\"))\n",
    "    \n",
    "    # concatenate all those data to create a large dataframe\n",
    "    state_df = pd.concat(state_list, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80cdca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if undone_flag:\n",
    "    state_df.to_csv(\".\\Processed_data\\States_mined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c348d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>likes_Mean</th>\n",
       "      <th>retweet_count_Mean</th>\n",
       "      <th>user_followers_count_Mean</th>\n",
       "      <th>TextBlob_Subjectivity_Mean</th>\n",
       "      <th>TextBlob_Polarity_Mean</th>\n",
       "      <th>likes_Skewness</th>\n",
       "      <th>retweet_count_Skewness</th>\n",
       "      <th>user_followers_count_Skewness</th>\n",
       "      <th>TextBlob_Subjectivity_Skewness</th>\n",
       "      <th>...</th>\n",
       "      <th>likes_Variance</th>\n",
       "      <th>retweet_count_Variance</th>\n",
       "      <th>user_followers_count_Variance</th>\n",
       "      <th>TextBlob_Subjectivity_Variance</th>\n",
       "      <th>TextBlob_Polarity_Variance</th>\n",
       "      <th>likes_Std</th>\n",
       "      <th>retweet_count_Std</th>\n",
       "      <th>user_followers_count_Std</th>\n",
       "      <th>TextBlob_Subjectivity_Std</th>\n",
       "      <th>TextBlob_Polarity_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>3.967799</td>\n",
       "      <td>0.972482</td>\n",
       "      <td>6975.041569</td>\n",
       "      <td>0.336137</td>\n",
       "      <td>0.083791</td>\n",
       "      <td>15.354061</td>\n",
       "      <td>14.302827</td>\n",
       "      <td>3.665861</td>\n",
       "      <td>0.460725</td>\n",
       "      <td>...</td>\n",
       "      <td>480.156549</td>\n",
       "      <td>28.248217</td>\n",
       "      <td>4.161292e+08</td>\n",
       "      <td>0.107459</td>\n",
       "      <td>0.082238</td>\n",
       "      <td>21.912475</td>\n",
       "      <td>5.314905</td>\n",
       "      <td>20399.244962</td>\n",
       "      <td>0.327809</td>\n",
       "      <td>0.286772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1.191977</td>\n",
       "      <td>0.292264</td>\n",
       "      <td>3201.982808</td>\n",
       "      <td>0.331841</td>\n",
       "      <td>0.061126</td>\n",
       "      <td>8.201224</td>\n",
       "      <td>22.596758</td>\n",
       "      <td>4.311367</td>\n",
       "      <td>0.327775</td>\n",
       "      <td>...</td>\n",
       "      <td>18.468113</td>\n",
       "      <td>5.908721</td>\n",
       "      <td>1.100722e+08</td>\n",
       "      <td>0.090065</td>\n",
       "      <td>0.069299</td>\n",
       "      <td>4.297454</td>\n",
       "      <td>2.430786</td>\n",
       "      <td>10491.530379</td>\n",
       "      <td>0.300108</td>\n",
       "      <td>0.263247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>5.016849</td>\n",
       "      <td>1.124816</td>\n",
       "      <td>2947.507443</td>\n",
       "      <td>0.321295</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>38.970872</td>\n",
       "      <td>27.822626</td>\n",
       "      <td>22.353001</td>\n",
       "      <td>0.517254</td>\n",
       "      <td>...</td>\n",
       "      <td>5229.406293</td>\n",
       "      <td>184.669137</td>\n",
       "      <td>1.487521e+08</td>\n",
       "      <td>0.096776</td>\n",
       "      <td>0.080643</td>\n",
       "      <td>72.314634</td>\n",
       "      <td>13.589302</td>\n",
       "      <td>12196.398804</td>\n",
       "      <td>0.311089</td>\n",
       "      <td>0.283978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.371534</td>\n",
       "      <td>0.411275</td>\n",
       "      <td>4821.268022</td>\n",
       "      <td>0.324972</td>\n",
       "      <td>0.072690</td>\n",
       "      <td>8.065272</td>\n",
       "      <td>7.333190</td>\n",
       "      <td>5.191989</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>...</td>\n",
       "      <td>21.512158</td>\n",
       "      <td>2.621630</td>\n",
       "      <td>4.261761e+08</td>\n",
       "      <td>0.100653</td>\n",
       "      <td>0.068388</td>\n",
       "      <td>4.638120</td>\n",
       "      <td>1.619145</td>\n",
       "      <td>20644.033938</td>\n",
       "      <td>0.317258</td>\n",
       "      <td>0.261510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>5.424561</td>\n",
       "      <td>1.239721</td>\n",
       "      <td>7322.299407</td>\n",
       "      <td>0.318791</td>\n",
       "      <td>0.066259</td>\n",
       "      <td>95.096283</td>\n",
       "      <td>104.154739</td>\n",
       "      <td>32.793312</td>\n",
       "      <td>0.514186</td>\n",
       "      <td>...</td>\n",
       "      <td>13503.820612</td>\n",
       "      <td>1238.382601</td>\n",
       "      <td>1.146873e+10</td>\n",
       "      <td>0.099220</td>\n",
       "      <td>0.079340</td>\n",
       "      <td>116.205941</td>\n",
       "      <td>35.190661</td>\n",
       "      <td>107092.171878</td>\n",
       "      <td>0.314991</td>\n",
       "      <td>0.281674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE_NAME  likes_Mean  retweet_count_Mean  user_followers_count_Mean  \\\n",
       "0     Alabama    3.967799            0.972482                6975.041569   \n",
       "1      Alaska    1.191977            0.292264                3201.982808   \n",
       "2     Arizona    5.016849            1.124816                2947.507443   \n",
       "3    Arkansas    1.371534            0.411275                4821.268022   \n",
       "4  California    5.424561            1.239721                7322.299407   \n",
       "\n",
       "   TextBlob_Subjectivity_Mean  TextBlob_Polarity_Mean  likes_Skewness  \\\n",
       "0                    0.336137                0.083791       15.354061   \n",
       "1                    0.331841                0.061126        8.201224   \n",
       "2                    0.321295                0.068841       38.970872   \n",
       "3                    0.324972                0.072690        8.065272   \n",
       "4                    0.318791                0.066259       95.096283   \n",
       "\n",
       "   retweet_count_Skewness  user_followers_count_Skewness  \\\n",
       "0               14.302827                       3.665861   \n",
       "1               22.596758                       4.311367   \n",
       "2               27.822626                      22.353001   \n",
       "3                7.333190                       5.191989   \n",
       "4              104.154739                      32.793312   \n",
       "\n",
       "   TextBlob_Subjectivity_Skewness  ...  likes_Variance  \\\n",
       "0                        0.460725  ...      480.156549   \n",
       "1                        0.327775  ...       18.468113   \n",
       "2                        0.517254  ...     5229.406293   \n",
       "3                        0.466071  ...       21.512158   \n",
       "4                        0.514186  ...    13503.820612   \n",
       "\n",
       "   retweet_count_Variance  user_followers_count_Variance  \\\n",
       "0               28.248217                   4.161292e+08   \n",
       "1                5.908721                   1.100722e+08   \n",
       "2              184.669137                   1.487521e+08   \n",
       "3                2.621630                   4.261761e+08   \n",
       "4             1238.382601                   1.146873e+10   \n",
       "\n",
       "   TextBlob_Subjectivity_Variance  TextBlob_Polarity_Variance   likes_Std  \\\n",
       "0                        0.107459                    0.082238   21.912475   \n",
       "1                        0.090065                    0.069299    4.297454   \n",
       "2                        0.096776                    0.080643   72.314634   \n",
       "3                        0.100653                    0.068388    4.638120   \n",
       "4                        0.099220                    0.079340  116.205941   \n",
       "\n",
       "   retweet_count_Std  user_followers_count_Std  TextBlob_Subjectivity_Std  \\\n",
       "0           5.314905              20399.244962                   0.327809   \n",
       "1           2.430786              10491.530379                   0.300108   \n",
       "2          13.589302              12196.398804                   0.311089   \n",
       "3           1.619145              20644.033938                   0.317258   \n",
       "4          35.190661             107092.171878                   0.314991   \n",
       "\n",
       "   TextBlob_Polarity_Std  \n",
       "0               0.286772  \n",
       "1               0.263247  \n",
       "2               0.283978  \n",
       "3               0.261510  \n",
       "4               0.281674  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a3bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905a8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb0f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669ac7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee975d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
